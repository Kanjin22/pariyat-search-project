คู่มือการดูแลและอัปเดตเว็บไซต์ค้นหารายชื่อ
วันที่สร้าง: 21/09/2025
ผู้จัดทำ: Kanjin22 (และผู้ออกแบบเว็บ)
URL เว็บไซต์: https://pariyat-search.onrender.com

---------------------------------------------------

ส่วนที่ 1: การทำงานบนเครื่อง PC (สำหรับการทดสอบและพัฒนา)
ใช้ส่วนนี้เมื่อต้องการทดสอบระบบทั้งหมดบนเครื่องคอมพิวเตอร์ของคุณเอง (มีปุ่มอัปเดต)

คำสั่งสำหรับเปิดเว็บ:
เปิด Command Prompt
พิมพ์: D: (แล้วกด Enter)
พิมพ์: cd pariyat-search-project\app (แล้วกด Enter)
พิมพ์: python app.py (แล้วกด Enter)
เปิดเบราว์เซอร์แล้วไปที่ http://127.0.0.1:5000

---------------------------------------------------

ส่วนที่ 2: การอัปเดตข้อมูลบนเว็บไซต์ออนไลน์ (สำคัญที่สุด)
ทำตามขั้นตอนนี้ทุกครั้งเมื่อมีรายชื่อผู้สมัครใหม่ หรือต้องการให้ข้อมูลบนเว็บออนไลน์เป็นเวอร์ชันล่าสุด

ขั้นตอนที่ 1: สร้างไฟล์ข้อมูลใหม่ล่าสุด
เปิด Command Prompt
พิมพ์: D: (แล้วกด Enter)
พิมพ์: cd pariyat-search-project\scraper (แล้วกด Enter)
พิมพ์: python scraper.py (แล้วกด Enter)
รอจนกว่าโปรแกรมจะทำงานเสร็จและขึ้นข้อความว่า "บันทึกข้อมูลเรียบร้อย!"

ขั้นตอนที่ 2: อัปโหลดข้อมูลใหม่ขึ้นสู่ระบบออนไลน์
(ใช้หน้าต่าง Command Prompt เดิม หรือเปิดใหม่ก็ได้)
พิมพ์: D: (แล้วกด Enter)
พิมพ์: cd pariyat-search-project (แล้วกด Enter)
รัน 3 คำสั่งต่อไปนี้ทีละบรรทัด:
git add . (แล้วกด Enter)
git commit -m "Update applicant data" (แล้วกด Enter)
git push origin main (แล้วกด Enter)

หลังจากรันคำสั่งสุดท้ายเสร็จ:
ให้เข้าไปที่เว็บไซต์ https://pariyat-search.onrender.com
ไปที่เมนู "Events" หรือ "Logs"
คุณจะเห็นว่ามี "Deploy in progress..." กำลังทำงานอยู่
รอประมาณ 2-3 นาทีจนกว่า Deploy จะเสร็จสมบูรณ์
เมื่อเสร็จแล้ว เว็บไซต์ของคุณก็จะแสดงข้อมูลล่าสุดโดยอัตโนมัติ


หมายเหตุและเกร็ดความรู้
คำสั่ง git commit -m "Update applicant data": คุณสามารถเปลี่ยนข้อความในเครื่องหมายคำพูด "" เป็นอะไรก็ได้เพื่อบันทึกว่าการอัปเดตครั้งนี้เกี่ยวกับอะไร เช่น "Update data 21-09-2025"
ไฟล์ class_links.txt: หากในอนาคตมีหน้าเว็บชั้นเรียนเพิ่มขึ้นมาใหม่ คุณเพียงแค่เพิ่ม URL ของหน้านั้นเข้าไปในไฟล์ class_links.txt (ในโฟลเดอร์ scraper) แล้วทำตามขั้นตอนการอัปเดตข้อมูลตามปกติได้เลย
ไม่ต้องลบไฟล์เก่า: โปรแกรม scraper.py และ git ถูกออกแบบมาให้ทำงานทับของเดิมและจัดการการเปลี่ยนแปลงให้โดยอัตโนมัติ
